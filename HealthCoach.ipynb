{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXtDLIYxzg8_",
        "outputId": "c0280662-f17b-4f55-d6f8-473a30ccbb16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.6)\n",
            "Requirement already satisfied: langchain-aws in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.59)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.12.0)\n",
            "Requirement already satisfied: boto3>=1.42.5 in /usr/local/lib/python3.12/dist-packages (from langchain-aws) (1.42.23)\n",
            "Requirement already satisfied: numpy<3,>=2.2 in /usr/local/lib/python3.12/dist-packages (from langchain-aws) (2.4.0)\n",
            "Requirement already satisfied: botocore<1.43.0,>=1.42.23 in /usr/local/lib/python3.12/dist-packages (from boto3>=1.42.5->langchain-aws) (1.42.23)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3>=1.42.5->langchain-aws) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from boto3>=1.42.5->langchain-aws) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.43.0,>=1.42.23->boto3>=1.42.5->langchain-aws) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.43.0,>=1.42.23->boto3>=1.42.5->langchain-aws) (2.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.23->boto3>=1.42.5->langchain-aws) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain langchain-core langchain-aws"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To Do: Update the access key ID and access key\n",
        "\n",
        "import os\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"\"\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"\"\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\""
      ],
      "metadata": {
        "id": "4ys7GIzl0xoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import botocore\n",
        "\n",
        "session = boto3.Session()\n",
        "bedrock_client = session.client('bedrock-agent')\n",
        "bedrock_runtime = boto3.client('bedrock-runtime')\n",
        "\n",
        "try:\n",
        "    response = bedrock_client.list_knowledge_bases(maxResults=1)  # Retrieve the first knowledge base\n",
        "    knowledge_base_summaries = response.get('knowledgeBaseSummaries', [])\n",
        "\n",
        "    if knowledge_base_summaries:\n",
        "        kb_id = knowledge_base_summaries[0]['knowledgeBaseId']\n",
        "        print(f\"Knowledge Base ID: {kb_id}\")\n",
        "    else:\n",
        "        print(\"No Knowledge Base summaries found.\")\n",
        "\n",
        "except botocore.exceptions.ClientError as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1UaHlFw0uXd",
        "outputId": "1430a5da-3184-4089-b08f-21e1ffa7fecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Knowledge Base ID: 5O0E4XEJBP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "from botocore.client import Config\n",
        "import pprint\n",
        "import json\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=2)\n",
        "\n",
        "session = boto3.session.Session()\n",
        "region = session.region_name\n",
        "\n",
        "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
        "bedrock_client = boto3.client('bedrock-runtime', region_name = region)\n",
        "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\", config=bedrock_config, region_name = region)"
      ],
      "metadata": {
        "id": "RH8vc_Ty1MdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "\n",
        "REGION = \"us-west-2\"\n",
        "bedrock = boto3.client(\"bedrock\", region_name=REGION)\n",
        "\n",
        "target_model_id = \"anthropic.claude-haiku-4-5-20251001-v1:0\"\n",
        "\n",
        "profiles = []\n",
        "resp = bedrock.list_inference_profiles(maxResults=100)\n",
        "profiles += resp.get(\"inferenceProfileSummaries\", [])\n",
        "while \"nextToken\" in resp:\n",
        "    resp = bedrock.list_inference_profiles(maxResults=100, nextToken=resp[\"nextToken\"])\n",
        "    profiles += resp.get(\"inferenceProfileSummaries\", [])\n",
        "\n",
        "match = None\n",
        "for p in profiles:\n",
        "    for m in p.get(\"models\", []):\n",
        "        if m.get(\"modelArn\", \"\").endswith(target_model_id):\n",
        "            match = p\n",
        "            break\n",
        "    if match:\n",
        "        break\n",
        "\n",
        "if not match:\n",
        "    raise RuntimeError(\"No inference profile found that contains the target model.\")\n",
        "\n",
        "inference_profile_id_or_arn = match.get(\"inferenceProfileArn\") or match.get(\"inferenceProfileId\")\n",
        "print(\"Using inference profile:\", inference_profile_id_or_arn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SihuyuH4gMy",
        "outputId": "47f9f637-72d6-41f0-8313-53caeeda140e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using inference profile: arn:aws:bedrock:us-west-2:471112956049:inference-profile/us.anthropic.claude-haiku-4-5-20251001-v1:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelId = inference_profile_id_or_arn"
      ],
      "metadata": {
        "id": "dlGp0dOR1kmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "from langchain_aws import ChatBedrock\n",
        "from langchain_aws.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
        "\n",
        "llm = ChatBedrock(model_id=modelId, provider=\"anthropic\", client=bedrock_runtime)"
      ],
      "metadata": {
        "id": "Hn00WxrZ1Y5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What helps headaches?\"\n",
        "retriever = AmazonKnowledgeBasesRetriever(\n",
        "        knowledge_base_id=kb_id,\n",
        "        retrieval_config={\"vectorSearchConfiguration\": {\"numberOfResults\": 4, 'overrideSearchType': \"SEMANTIC\"}})\n",
        "docs = retriever.invoke(\n",
        "        input=query\n",
        "    )\n",
        "#for doc in docs:\n",
        "#    print(doc.page_content)\n",
        "#    print(\"------\")"
      ],
      "metadata": {
        "id": "06HO3MoE1vW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "You are a behavioral health coach who has been provided mental health information about a specific patient.\n",
        "You should speak in a compassionate, professional tone to support the user. Make sure to not share\n",
        "information about the patient in the context, and only focus on providing advice.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Make sure the response contains:\n",
        "-Actionable advice\n",
        "-Less than 150 words\n",
        "\n",
        "If certain information is not available in the provided context, explicitly state: \"This information is not provided.\"\n",
        "Stick to the responses provided in the context.\n",
        "\"\"\"\n",
        "\n",
        "claude_prompt = PromptTemplate(template=PROMPT_TEMPLATE,\n",
        "                               input_variables=[\"context\",\"question\"])"
      ],
      "metadata": {
        "id": "BLFbR3Qp3alj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | claude_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "response=chain.invoke(query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VJ80aSg3Pyg",
        "outputId": "6bbe51a4-c70e-4212-f93d-c5f12ed6e18e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Managing Headaches: Practical Strategies\n",
            "\n",
            "Here are evidence-based approaches that can help:\n",
            "\n",
            "**Prevention:**\n",
            "- Take magnesium and riboflavin (B2) supplements regularly\n",
            "- Ensure quality sleep and continue exercising\n",
            "- Get annual lab work (thyroid, vitamin D, B12 levels)\n",
            "\n",
            "**Daily habits:**\n",
            "- Reduce screen brightness and use a blue light filter\n",
            "- Take breaks every 20 minutes—look at something distant to ease eye strain\n",
            "- Stay hydrated and manage stress\n",
            "\n",
            "**Pain management:**\n",
            "- Limit over-the-counter pain relievers to 1-2 times monthly (frequent use can worsen headaches)\n",
            "- Avoid ibuprofen and Tylenol if you have migraines; consider alternatives like NeuroMag instead\n",
            "\n",
            "**When to seek help:**\n",
            "- If lifestyle changes don't improve symptoms, consult your healthcare provider about prescription preventative options\n",
            "- Track your headaches to identify patterns and triggers\n",
            "\n",
            "Remember, headaches are manageable with a comprehensive approach combining prevention, lifestyle modifications, and professional support when needed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Gradio ###\n",
        "\n",
        "import os\n",
        "import boto3\n",
        "import botocore\n",
        "from botocore.config import Config\n",
        "import gradio as gr\n",
        "\n",
        "from langchain_aws import ChatBedrock\n",
        "from langchain_aws.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "REGION = \"us-west-2\"\n",
        "TARGET_MODEL_ID = \"anthropic.claude-haiku-4-5-20251001-v1:0\"\n",
        "\n",
        "cfg = Config(connect_timeout=120, read_timeout=120, retries={\"max_attempts\": 0})\n",
        "\n",
        "bedrock_control = boto3.client(\"bedrock\", region_name=REGION)                  # list inference profiles\n",
        "bedrock_agent = boto3.client(\"bedrock-agent\", region_name=REGION)              # list KBs\n",
        "bedrock_agent_runtime = boto3.client(\"bedrock-agent-runtime\", region_name=REGION, config=cfg)  # retrieve\n",
        "bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=REGION, config=cfg)             # invoke model\n",
        "\n",
        "def get_first_kb_id() -> str:\n",
        "    resp = bedrock_agent.list_knowledge_bases(maxResults=1)\n",
        "    summaries = resp.get(\"knowledgeBaseSummaries\", [])\n",
        "    if not summaries:\n",
        "        raise RuntimeError(\"No Knowledge Bases found in this account/region.\")\n",
        "    return summaries[0][\"knowledgeBaseId\"]\n",
        "\n",
        "def get_inference_profile_for_model(target_model_id: str) -> str:\n",
        "    profiles = []\n",
        "    resp = bedrock_control.list_inference_profiles(maxResults=100)\n",
        "    profiles += resp.get(\"inferenceProfileSummaries\", [])\n",
        "\n",
        "    while \"nextToken\" in resp:\n",
        "        resp = bedrock_control.list_inference_profiles(maxResults=100, nextToken=resp[\"nextToken\"])\n",
        "        profiles += resp.get(\"inferenceProfileSummaries\", [])\n",
        "\n",
        "    for p in profiles:\n",
        "        for m in p.get(\"models\", []):\n",
        "            if m.get(\"modelArn\", \"\").endswith(target_model_id):\n",
        "                return p.get(\"inferenceProfileArn\") or p.get(\"inferenceProfileId\")\n",
        "\n",
        "    raise RuntimeError(f\"No inference profile found that contains: {target_model_id}\")\n",
        "\n",
        "kb_id = get_first_kb_id()\n",
        "inference_profile_id_or_arn = get_inference_profile_for_model(TARGET_MODEL_ID)\n",
        "\n",
        "llm = ChatBedrock(model_id=inference_profile_id_or_arn, provider=\"anthropic\", client=bedrock_runtime)\n",
        "\n",
        "retriever = AmazonKnowledgeBasesRetriever(knowledge_base_id=kb_id, retrieval_config={\n",
        "        \"vectorSearchConfiguration\": {\n",
        "            \"numberOfResults\": 4,\n",
        "            \"overrideSearchType\": \"SEMANTIC\",\n",
        "        }\n",
        "    },\n",
        ")\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "You are a behavioral health coach who has been provided mental health information about a specific patient.\n",
        "You should speak in a compassionate, professional tone to support the user. Make sure to not share\n",
        "information about the patient in the context, and only focus on providing advice.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Make sure the response contains:\n",
        "- Actionable advice\n",
        "- Less than 150 words\n",
        "\n",
        "If certain information is not available in the provided context, explicitly state: \"This information is not provided.\"\n",
        "Stick to the responses provided in the context.\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=PROMPT_TEMPLATE, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(d.page_content for d in docs)\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "\n",
        "def chat(user_message: str, history):\n",
        "    user_message = (user_message or \"\").strip()\n",
        "    if not user_message:\n",
        "        return \"\", history\n",
        "\n",
        "    try:\n",
        "        answer = chain.invoke(user_message)\n",
        "        history = history + [[user_message, answer]]\n",
        "        return \"\", history\n",
        "    except botocore.exceptions.ClientError as e:\n",
        "        err = f\"AWS error: {e}\"\n",
        "        history = history + [[user_message, err]]\n",
        "        return \"\", history\n",
        "    except Exception as e:\n",
        "        err = f\"Error: {repr(e)}\"\n",
        "        history = history + [[user_message, err]]\n",
        "        return \"\", history\n",
        "\n",
        "with gr.Blocks(title=\"Bedrock Knowledge Base Coach\") as demo:\n",
        "    gr.Markdown(\n",
        "        f\"\"\"\n",
        "# Bedrock Knowledge Base Chat (Claude via Inference Profile)\n",
        "\n",
        "**Region:** `{REGION}`\n",
        "**Knowledge Base:** `{kb_id}`\n",
        "**Model (Inference Profile):** `{inference_profile_id_or_arn}`\n",
        "\n",
        "Ask a question and I’ll answer using your Knowledge Base context.\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "    chatbot = gr.Chatbot(height=420)\n",
        "    msg = gr.Textbox(label=\"Your message\", placeholder=\"e.g., In what ways is green tea helpful?\", lines=2)\n",
        "    clear = gr.Button(\"Clear\")\n",
        "\n",
        "    msg.submit(chat, [msg, chatbot], [msg, chatbot])\n",
        "    clear.click(lambda: [], None, chatbot)\n",
        "\n",
        "demo.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "wIwIeUpR8Jgz",
        "outputId": "0bfc4d08-608b-4e7d-bd77-c6b8a5d4ace8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-222918445.py:159: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(height=420)\n",
            "/tmp/ipython-input-222918445.py:159: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chatbot = gr.Chatbot(height=420)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://53da691e689f0fb8e2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://53da691e689f0fb8e2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://53da691e689f0fb8e2.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V9Rgl3Ni8R52"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}